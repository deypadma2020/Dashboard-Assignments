{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMafJvun/ccpwGhJC+REQRS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. In the sense of machine learning, what is a model? What is the best way to train a model?"],"metadata":{"id":"4TKtICzeefzh"}},{"cell_type":"markdown","source":["Ans: -\n","\n","- A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.\n","- Training a model simply means learning good values for all the weights and the bias from labeled examples. In supervised learning, a machine learning algorithm builds a model by examining many examples and attempting to find a model that minimizes loss; this process is called empirical risk minimization.\n","\n","  Step 1: Begin with existing data. Machine learning requires us to have existing data—not the data our application will use when we run it, but data to learn from. ...\n","\n","  Step 2: Analyze data to identify patterns. ...\n","\n","  Step 3: Make predictions."],"metadata":{"id":"dUnwBqK2eflC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yaiq2L4CbOhK"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## 2. In the sense of machine learning, explain the &quot;No Free Lunch&quot; theorem."],"metadata":{"id":"oFo0jeqyejfm"}},{"cell_type":"markdown","source":["Ans: -\n","\n","The “no free lunch” (NFL) theorem for supervised machine learning is a theorem that essentially implies that no single machine learning algorithm is universally the best-performing algorithm for all problems."],"metadata":{"id":"3-KLcS-oei6g"}},{"cell_type":"code","source":[],"metadata":{"id":"mNFjgLZmen3U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Describe the K-fold cross-validation mechanism in detail."],"metadata":{"id":"I6pKarBYeoY5"}},{"cell_type":"markdown","source":["Ans: -\n","\n","K-fold Cross-Validation is when the dataset is split into a K number of folds and is used to evaluate the model's ability when given new data. K refers to the number of groups the data sample is split into. For example, if you see that the k-value is 5, we can call this a 5-fold cross-validation."],"metadata":{"id":"72SPPPT_eoVX"}},{"cell_type":"code","source":[],"metadata":{"id":"dTY2ApXeet7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Describe the bootstrap sampling method. What is the aim of it?"],"metadata":{"id":"bD-dHIB9evGB"}},{"cell_type":"markdown","source":["Ans: -\n","\n","- Bootstrapping is a method of inferring results for a population from results found on a collection of smaller random samples of that population, using replacement during the sampling process.\n","- Bootstrapping assigns measures of accuracy (bias, variance, confidence intervals, prediction error, etc.) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods."],"metadata":{"id":"grY5j-rCeubQ"}},{"cell_type":"code","source":[],"metadata":{"id":"dLq_UPrwe0Fr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results."],"metadata":{"id":"qDNCjm-ae0kF"}},{"cell_type":"markdown","source":["Ans: -\n","\n","- The kappa score is an interesting metric. Its origins are in the field of psychology: it is used for measuring the agreement between two human evaluators or raters (e.g., psychologists) when rating subjects (patients). It was later “appropriated” by the machine-learning community to measure classification performance.\n","- To calculate the Kappa coefficient we will take the probability of agreement minus the probability of disagreement divided by 1 minus the probability of disagreement. This is a positive value which means there is some mutual agreement between the parties. Let us now implement this with sklearn and check the value."],"metadata":{"id":"vrUpxijOe0gv"}},{"cell_type":"code","source":[],"metadata":{"id":"DtLVfsE6e6Ul"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Describe the model ensemble method. In machine learning, what part does it play?"],"metadata":{"id":"-j6XxjO1e6zP"}},{"cell_type":"markdown","source":["Ans: -\n","\n","- Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data.\n","- In this ensemble technique, machine learning professionals use a number of models for making predictions about each data point. The predictions made by different models are taken as separate votes. Subsequently, the prediction made by most models is treated as the ultimate prediction.\n","\n"],"metadata":{"id":"h7sl2HMse6ul"}},{"cell_type":"code","source":[],"metadata":{"id":"jh1Ajaiue__c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve."],"metadata":{"id":"75aWKoBEfCJl"}},{"cell_type":"markdown","source":["Ans: -\n","\n","- A descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it. A geometric model or spatial model is a descriptive model that represents geometric and/or spatial relationships.\n","- Company reports tracking inventory, workflow, sales and revenue are all examples of descriptive analytics. Other examples include KPIs and metrics used to measure the performance of specific aspects of the business or the company overall."],"metadata":{"id":"0f_-CwHyfCF_"}},{"cell_type":"code","source":[],"metadata":{"id":"FQeSmoBMfK2o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. Describe how to evaluate a linear regression model."],"metadata":{"id":"oNzo0vNGfLjY"}},{"cell_type":"markdown","source":["Ans: -\n","\n","Linear Regression Analysis consists of more than just fitting a linear line through a cloud of data points. It consists of 3 stages – \n","1. analyzing the correlation and directionality of the data, \n","2. estimating the model, i.e., fitting the line, and \n","3. evaluating the validity and usefulness of the model."],"metadata":{"id":"dCxCMP52fLf4"}},{"cell_type":"code","source":[],"metadata":{"id":"HoNjVjMvfQvP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. Distinguish :\n","\n","1. Descriptive vs. predictive models\n","\n","2. Underfitting vs. overfitting the model\n","\n","3. Bootstrapping vs. cross-validation"],"metadata":{"id":"Z0L38OOvfRbA"}},{"cell_type":"markdown","source":["Ans: -\n","\n","1. The descriptive analysis only responds to the situation. The predictive analysis includes control over the situation along with responding to it. It can support accurate records. It makes results does not provide accuracy.\n","\n","  Models that are primarily used for understanding, predicting and communicating are referred to as descriptive models, whereas models mainly used for implementation are called prescriptive models. This contribution focuses on teaching both the common and the distinguishing aspects of the two model categories.\n","\n","  Descriptive mining is usually used to provide correlation, cross-tabulation, frequency, etc. The term 'Predictive' means to predict something, so predictive data mining is the analysis done to predict the future event or other data or trends. It is based on the reactive approach. It is based on the proactive approach.\n","2. A model that is underfit will have high training and high testing error while an overfit model will have extremely low training error but a high testing error.\n","\n","  Overfitting means that the neural network performs very well on training data, but fails as soon it sees some new data from the problem domain. Underfitting, on the other hand, means, that the model performs poorly on both datasets.\n","3. In summary, Cross validation splits the available dataset to create multiple datasets, and Bootstrapping method uses the original dataset to create multiple datasets after resampling with replacement. Bootstrapping it is not as strong as Cross validation when it is used for model validation."],"metadata":{"id":"IpxWbAZCfRMY"}},{"cell_type":"code","source":[],"metadata":{"id":"SdcRiw0PfXPD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Make quick notes on:\n","\n","1. LOOCV.\n","\n","2. F-measurement\n","\n","3. The width of the silhouette\n","\n","4. Receiver operating characteristic curve"],"metadata":{"id":"D4Fjh5BffYCm"}},{"cell_type":"markdown","source":["Ans: -\n","\n","1. LOOCV(Leave One Out Cross-Validation) is a type of cross-validation approach in which each observation is considered as the validation set and the rest (N-1) observations are considered as the training set. In LOOCV, fitting of the model is done and predicting using one observation validation set.\n","2. The F-measure of the system is defined as the weighted harmonic mean of its precision and recall, that is, F = {1\\over \\alpha {1\\over P}+(1-\\alpha ) {1\\over R}}, where the weight α ∈ [0,1]. The balanced F-measure, commonly denoted as F 1 or just F, equally weighs precision and recall, which means α = 1∕2.\n","3. Silhouette width is a widely used index for assessing the fit of individual objects in the classification, as well as the quality of clusters and the entire classification.\n","4. \n","The receiver operating characteristic (ROC) curve, which is defined as a plot of test sensitivity as the y coordinate versus its 1-specificity or false positive rate (FPR) as the x coordinate, is an effective method of evaluating the performance of diagnostic tests."],"metadata":{"id":"9Bsq-N-OfX_N"}},{"cell_type":"code","source":[],"metadata":{"id":"TFij-hhdfeDE"},"execution_count":null,"outputs":[]}]}