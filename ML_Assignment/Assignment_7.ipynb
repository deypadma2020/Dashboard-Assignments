{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?"
      ],
      "metadata": {
        "id": "45LqwbEKrwXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results (predictive analysis).\n",
        "- Image recognition is a well-known and widespread example of machine learning in the real world. It can identify an object as a digital image, based on the intensity of the pixels in black and white images or colour images. Real-world examples of image recognition: Label an x-ray as cancerous or not.\n",
        "- Fitness Function (also known as the Evaluation Function) evaluates how close a given solution is to the optimum solution of the desired problem. It determines how fit a solution is."
      ],
      "metadata": {
        "id": "3Q7bm3NYrwC7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5PlJF97rneN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models."
      ],
      "metadata": {
        "id": "_09ure03r4qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- Predictive modeling is a commonly used statistical technique to predict future behavior. Predictive modeling solutions are a form of data-mining technology that works by analyzing historical and current data and generating a model to help predict future outcomes.\n",
        "- Descriptive studies can be of several types, namely, case reports, case series, cross-sectional studies, and ecological studies. In the first three of these, data are collected on individuals, whereas the last one uses aggregated data for groups.\n",
        "\n",
        "  Steps to conduct a descriptive research design --\n",
        "\n",
        "Step-1: Outline the research objective. ...\n",
        "\n",
        "Step-2: Determine the tools and techniques to be used for data collection. ...\n",
        "\n",
        "Step-3: Define​​ the target population and sample group. ...\n",
        "\n",
        "Step-4: Select a method for data collection. ...\n",
        "\n",
        "Step-5: Analyse the data collected. ...\n",
        "\n",
        "Step-6: Write the report.\n",
        "\n",
        "- In unsupervised learning, the data mining algorithms describe some intrinsic property or structure of data and hence are sometimes called descriptive models. On the other hand, supervised learning techniques typically use a model to predict the value or behavior of some quantity and are hence called predictive models.\n",
        "- Examples include using neural networks to predict which winery a glass of wine originated from or bagged decision trees for predicting the credit rating of a borrower. Predictive modeling is often performed using curve and surface fitting, time series regression, or machine learning approaches. "
      ],
      "metadata": {
        "id": "Ghc1D51mr4G1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5pBjXVusAFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters."
      ],
      "metadata": {
        "id": "BEnYGpxOsAhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- Metrics like accuracy, precision, recall are good ways to evaluate classification models for balanced datasets, but if the data is imbalanced then other methods like ROC/AUC perform better in evaluating the model performance.\n",
        "- A model parameter is a configuration variable that is internal to the model and whose value can be estimated from the given data. They are required by the model when making predictions. Their values define the skill of the model on your problem."
      ],
      "metadata": {
        "id": "ToQAkfY6sAdp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpA7I1tKsIet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.\n",
        "i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
        "\n",
        "ii. What does it mean to overfit? When is it going to happen?\n",
        "\n",
        "iii. In the sense of model fitting, explain the bias-variance trade-off."
      ],
      "metadata": {
        "id": "56D-2hRMsJS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data.\n",
        "\n",
        "  It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization. Like overfitting, when a model is underfitted, it cannot establish the dominant trend within the data, resulting in training errors and poor performance of the model.\n",
        "- Overfitting occurs when the model cannot generalize and fits too closely to the training dataset instead. Overfitting happens due to several reasons, such as: • The training data size is too small and does not contain enough data samples to accurately represent all possible input data values.\n",
        "- In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters."
      ],
      "metadata": {
        "id": "Jt-IsHhCsJPd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfOmEJyUsRY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how."
      ],
      "metadata": {
        "id": "SXoRDCx_sSCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "Improving the accuracy of a machine learning model is a skill that can only improve with practice. The more projects you build, the better your intuition will get about which approach you should use next time to improve your model's accuracy."
      ],
      "metadata": {
        "id": "ePINkz1UsR0b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OihisUosW0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?"
      ],
      "metadata": {
        "id": "JwIP8moPsXRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- Twin sample validation can be used to validate results of unsupervised learning. It should be used in combination with internal validation. It can prove to be highly useful in case of time-series data where we want to ensure that our results remain same across time.\n",
        "- A set of clusters having high cohesion within the clusters and high separation between the clusters is considered to be good. In practice, instead of dealing with two metrics, several measures are available which combine both of the above into a single measure. Few examples of such measures are: Silhouette coefficient."
      ],
      "metadata": {
        "id": "jAzHgOfxsep5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUoU-BmAsfIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer."
      ],
      "metadata": {
        "id": "e6tUwehrsfrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "The two most commonly used feature selection methods for categorical input data when the target variable is also categorical (e.g. classification predictive modeling) are the chi-squared statistic and the mutual information statistic."
      ],
      "metadata": {
        "id": "orvCfZt7sfoA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysUb1JFEslLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?"
      ],
      "metadata": {
        "id": "dGS0w9sGslmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "- In short, predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
        "- Predictive modeling is the process of taking known results and developing a model ... variable is continuous and the dependent variables are categorical."
      ],
      "metadata": {
        "id": "dyHkcWbTsljR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2hWwjhVsqf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
        "\n",
        "1. Accurate estimates – 15 cancerous, 75 benign\n",
        "2. Wrong predictions – 3 cancerous, 7 benign\n",
        "\n",
        "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure."
      ],
      "metadata": {
        "id": "eS82x8x8sq-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "1. error rate: 15\n",
        "2. Kappa value: 0.22\n",
        "3. sensitivity: 1.5\n",
        "4. precision: 2.14\n",
        "5. F-measure: 1.034 "
      ],
      "metadata": {
        "id": "H89aRq4qsq3b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2KHIghyos8m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make quick notes on:\n",
        "1. The process of holding out\n",
        "2. Cross-validation by tenfold\n",
        "3. Adjusting the parameters"
      ],
      "metadata": {
        "id": "UKRMjYXas_h5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "1. Holdout Method is the simplest sort of method to evaluate a classifier. In this method, the data set (a collection of data items or examples) is separated into two sets, called the Training set and Test set. A classifier performs function of assigning data items in a given collection to a target category or class.\n",
        "2. With this method we have one data set which we divide randomly into 10 parts. We use 9 of those parts for training and reserve one tenth for testing. We repeat this procedure 10 times each time reserving a different tenth for testing.\n",
        "3. 1. A parameter that determines the adjustment speed of a variable when a long-run disequilibrium occurs. It is estimated within a VEC model."
      ],
      "metadata": {
        "id": "aotQdnfns_ea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08SjEYqAtIxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Define the following terms:\n",
        "1. Purity vs. Silhouette width\n",
        "2. Boosting vs. Bagging\n",
        "3. The eager learner vs. the lazy learner"
      ],
      "metadata": {
        "id": "yhMxwz1ytJkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: -\n",
        "\n",
        "1. The main difference between the cluster purity and silhouette width is that the former ignores the intra-cluster variance.\n",
        "2. Bagging is a method of merging the same type of predictions. Boosting is a method of merging different types of predictions. Bagging decreases variance, not bias, and solves over-fitting issues in a model. Boosting decreases bias, not variance.\n",
        "3. Eager learning methods construct general, explicit description of the target function based on the provided training examples. Lazy learning methods simply store the data and generalizing beyond these data is postponed until an explicit request is made."
      ],
      "metadata": {
        "id": "B4N3GQSstJg-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHgvvIUytOW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}